{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf44680-b0f2-4ad4-8747-a0af7ef0ce46",
   "metadata": {},
   "source": [
    "## Importing MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22e9b6cc-a4bf-495c-9cb6-c7e412a19cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This is a sample Notebook to demonstrate how to read \"MNIST Dataset\"\n",
    "#\n",
    "import numpy as np # linear algebra\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())\n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33095f8-bf2b-40eb-aba2-2b7185088699",
   "metadata": {},
   "source": [
    "### Verifiying Dataset Was Loaded Correctly via MnistDataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa06b04-37d7-417d-86a0-70c89094e23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST\\train-images-idx3-ubyte/train-images-idx3-ubyte\n",
      "MNIST\\train-labels-idx1-ubyte/train-labels-idx1-ubyte\n",
      "MNIST\\t10k-images-idx3-ubyte/t10k-images-idx3-ubyte\n",
      "MNIST\\t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "# Set file paths based on added MNIST Datasets\n",
    "#\n",
    "input_path = 'MNIST'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte') #60,000 training images\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte') #10,000 test images\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "print(training_images_filepath)\n",
    "print(training_labels_filepath)\n",
    "print(test_images_filepath)\n",
    "print(test_labels_filepath)\n",
    "\n",
    "#\n",
    "# Helper function to show a list of images with their relating titles\n",
    "#\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray) # values go from 0 (black) to 256\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1\n",
    "\n",
    "#\n",
    "# Load MINST dataset\n",
    "#\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcbd486-7544-46ac-bb97-9614625c0c82",
   "metadata": {},
   "source": [
    "### Showing Some of the Images Based on Selected File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e04653b-07a1-4a10-a612-4e8b95867e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x2000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Show some random training and test images \n",
    "#\n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "for i in range(0, 1): # how many random training images you want to show\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(x_train[r])\n",
    "    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_train[r]))    \n",
    "\n",
    "for i in range(0, 1): # how many random test images you want to show\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test[r])        \n",
    "    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n",
    "\n",
    "show_images(images_2_show, titles_2_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc368a3a-62a2-4852-b056-d672a49bb01f",
   "metadata": {},
   "source": [
    "## Creating Neural Network (2 layers excluding the inputs)\n",
    "\n",
    "There will be 2 layers. The inputs will be 28 * 28 neurons or 784 in total, the hidden layer will have 300 neurons, and then the output will have 10 neurons representing the likihood of each digit in this classification problem after applying the softmax function to the logit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4070804f-b2e1-4000-87ae-79ace4b87f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters in neural network\n",
    "\n",
    "layers = [784, 300, 10]\n",
    "neurons_input, neurons_l1, neurons_output = layers[0], layers[1], layers[2]\n",
    "randomGen = np.random.default_rng(seed=42)\n",
    "\n",
    "W2 = randomGen.random((neurons_output, neurons_l1)) # 10 rows, 300 columns\n",
    "b2 = randomGen.random((neurons_output, 1))\n",
    "W1 = randomGen.random((neurons_l1, neurons_input)) #300 rows, 784 columns\n",
    "b1 = randomGen.random((neurons_l1, 1))\n",
    "\n",
    "p = [W2, b2, W1, b1]\n",
    "\n",
    "#Constructing and normalizing mini-batch to be input\n",
    "def GetMiniBatch(x_train, numInputs): \n",
    "    miniBatch = np.zeros((784,numInputs))\n",
    "    y_miniBatch = np.zeros((10,numInputs))\n",
    "    for i in range(numInputs):\n",
    "        r = random.randint(0, 60000 - 1) #we may sample the same images again from another batch but this will be fixed later on\n",
    "        temp = np.array(x_train[r])\n",
    "        y_miniBatch[y_train[r],i] = 1 #putting a 1 where the correct label is \n",
    "        temp = np.reshape(temp, 784) / 255 #normalize values to be between 0 and 1 or else we cannot exponentiate them for the softmax function\n",
    "        miniBatch[:,i] = temp\n",
    "    return miniBatch, y_miniBatch  #each column represents a sample\n",
    "\n",
    "miniBatch, y_miniBatch = GetMiniBatch(x_train, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af52150f-9f16-4075-b930-4f3a2753935b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Checking first layer if values are correct\\ntemp = np.matmul(W1, miniBatch)\\nz1 = temp + b1 # (300 X 784) X (784 X 100) + (300 X 1) => (300 X 100)\\nfor j in range(10):\\n    print(\"Checking that temp + b1 is correct for index {}, temp:{}, temp + b1: {}, z1: {}\".format(j, temp[0][j], temp[0][j] + b1[0], z1[0][j]))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Checking first layer if values are correct\n",
    "temp = np.matmul(W1, miniBatch)\n",
    "z1 = temp + b1 # (300 X 784) X (784 X 100) + (300 X 1) => (300 X 100)\n",
    "for j in range(10):\n",
    "    print(\"Checking that temp + b1 is correct for index {}, temp:{}, temp + b1: {}, z1: {}\".format(j, temp[0][j], temp[0][j] + b1[0], z1[0][j]))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e03ae6f-c6e0-4695-a931-6ad57a5a6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Checker - with respect to first element in W2 for now\n",
    "def GradientChecker(miniBatch, y_miniBatch, p, e):\n",
    "    W2 = p[0]\n",
    "    b2 = p[1]\n",
    "    W1 = p[2]\n",
    "    b1 = p[3]\n",
    "    \n",
    "    #J(W2 + e)\n",
    "    #First Layer\n",
    "    z1 = np.matmul(W1, miniBatch) + b1 # (300 X 784) X (784 X 100) + (300 X 1) => (300 X 100)\n",
    "    a1 = sigmoid(z1)\n",
    "    #Second layer\n",
    "    W2[0,0] += e\n",
    "    z2 = np.matmul(W2, a1) + b2 # LOGIT: (10 X 300) X (300 X 100) + (10 X 1) => (10 X 100) \n",
    "    #Softmax\n",
    "    rows, cols = z2.shape\n",
    "    softmax_denominator = np.zeros((rows,cols))\n",
    "    for i in range(cols):\n",
    "        denominator_sum = np.sum(np.exp(z2[:,i]))\n",
    "        softmax_denominator[:,i] = np.full(rows, denominator_sum)\n",
    "        \n",
    "    softmax = np.exp(z2) / softmax_denominator #final output normalized as probabilities\n",
    "    loss_1 = Loss(softmax, y_miniBatch)\n",
    "    \n",
    "    #J(W2 - e)\n",
    "    #First Layer\n",
    "    z1 = np.matmul(W1, miniBatch) + b1 # (300 X 784) X (784 X 100) + (300 X 1) => (300 X 100)\n",
    "    a1 = sigmoid(z1)\n",
    "    #Second layer\n",
    "    W2[0,0] -= e\n",
    "    z2 = np.matmul(W2, a1) + b2 # LOGIT: (10 X 300) X (300 X 100) + (10 X 1) => (10 X 100) \n",
    "    #Softmax\n",
    "    rows, cols = z2.shape\n",
    "    softmax_denominator = np.zeros((rows,cols))\n",
    "    for i in range(cols):\n",
    "        denominator_sum = np.sum(np.exp(z2[:,i]))\n",
    "        softmax_denominator[:,i] = np.full(rows, denominator_sum)\n",
    "    softmax = np.exp(z2) / softmax_denominator #final output normalized as probabilities\n",
    "    loss_2 = Loss(softmax, y_miniBatch)\n",
    "\n",
    "    return (loss_1 - loss_2)/ (2 * e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fbd5c0a-e80e-4936-ad6f-72f073654624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 5],\n",
       "       [4, 6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[3,4],[5,6]])\n",
    "b = np.array([[0,1],[1,0]])\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4cde00e-3877-4dac-9761-99dad0481876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Entropy Loss for specified minibatch\n",
    "def Loss(softmax, y_miniBatch):\n",
    "    # Softmax is (10 by 100) while y_miniBatch is (10 by 100) as well where y_miniBatch holds the one hot encoding\n",
    "    Loss_all_samples = -np.log(np.diag(np.matmul(y_miniBatch.T, softmax))) ## if the true probability distribution is a one hot encoding then formula reduces to -log(y_correct_label) or the negative log likelihood\n",
    "    return np.sum(Loss_all_samples) / y_miniBatch.shape[1] # loss over multiple samples is the average of all them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eee6a38-fdfc-4a12-9be6-97adc44b0577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Foward  and Backward Propagation (assuming 100 sample inputs)\n",
    "def sigmoid(z):\n",
    "    return (1/(1 + np.exp(-z)))\n",
    "            \n",
    "def sigmoidDeriv(z):\n",
    "    return (1 - sigmoid(z))\n",
    "\n",
    "def ForwardAndBackwardProp(miniBatch, y_miniBatch, p, learning_rate, layers):\n",
    "    W2 = p[0]\n",
    "    b2 = p[1]\n",
    "    W1 = p[2]\n",
    "    b1 = p[3]\n",
    "    \n",
    "    #First Layer\n",
    "    z1 = np.matmul(W1, miniBatch) + b1 # (300 X 784) X (784 X 100) + (300 X 1) => (300 X 100)\n",
    "    a1 = sigmoid(z1)\n",
    "    #Second layer\n",
    "    z2 = np.matmul(W2, a1) + b2 # LOGIT: (10 X 300) X (300 X 100) + (10 X 1) => (10 X 100) \n",
    "    #Softmax\n",
    "    rows, cols = z2.shape\n",
    "    softmax_denominator = np.zeros((rows,cols))\n",
    "    for i in range(cols):\n",
    "        denominator_sum = np.sum(np.exp(z2[:,i]))\n",
    "        softmax_denominator[:,i] = np.full(rows, denominator_sum)\n",
    "\n",
    "    softmax = np.exp(z2) / softmax_denominator #final output normalized as probabilities\n",
    "    #print(\"Sum of a column in softmax: {}\".format(np.sum(softmax[:,2]))) #checking a column of the final output equals 1\n",
    "   \n",
    "    # Backward Prop (Calculating Gradients)\n",
    "    num_inputs = miniBatch.shape[1]\n",
    "    localError_l2 = z2 - y_miniBatch # (10 by 100) => derivative of the cross entropy loss with respect to z2 assuming only a softmax is done on z2 is the p - y where is p is the logit and y is the one hot vetor for this classification task \n",
    "    dW2 = np.zeros((layers[2], layers[1]))\n",
    "    db2 = np.zeros((layers[2], 1))\n",
    "    db1 = np.zeros((layers[1],1))\n",
    "    dW1 = np.zeros((layers[1],layers[0]))\n",
    "    \n",
    "    db2 = (np.sum(localError_l2, axis=1)).reshape((10,1)) #Adding up the localerror along each row\n",
    "    dW2 = np.matmul(localError_l2, a1.T)\n",
    "    \n",
    "    localError_l1 = np.multiply(np.matmul(W2.T, localError_l2), sigmoidDeriv(z1)) #((300 by 10) X (10 by 100)) element_mult (300 by 100)\n",
    "    db1 = (np.sum(localError_l1, axis=1)).reshape((300,1))\n",
    "    dW1 = np.matmul(localError_l1, miniBatch.T) #(300 by 100) X (100 by 784)\n",
    "    #Checking Gradient\n",
    "    dW2_verified_00 = GradientChecker(miniBatch, y_miniBatch, p, 0.00001)\n",
    "    print(\"This is verified: {}, this is acutal: {}\".format(dW2_verified_00, dW2[0,0]/num_inputs))\n",
    "    print(\"Calculating dW2 another way: {}\".format(localError_l2[0,0] * a1[0,0]))\n",
    "    print(localError_l2)\n",
    "    print(a1)\n",
    "    #as of now, the gradients are inccorrect\n",
    "    \n",
    "    #Updating Parameters\n",
    "    derivParam = [dW2, db2, dW1, db1]\n",
    "    pNew = []\n",
    "    \n",
    "    for i in range(len(p)):\n",
    "        temp = derivParam[i]\n",
    "        temp /= num_inputs     #Normalizing derivative of loss with respect to different parameters since overall loss = average of the sum of each sample's loss\n",
    "        pNew.append(p[i] - (learning_rate * temp))\n",
    "    \n",
    "    return pNew, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "107128b4-c8d9-4a3d-b047-bac9b5475dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is verified: -0.049496228982093264, this is acutal: 146.7262671358587\n",
      "Calculating dW2 another way: 146.8252676219906\n",
      "[[146.82526762 146.82526762 146.82526762 ... 146.82526762 146.82526762\n",
      "  145.82526762]\n",
      " [152.18998053 152.18998053 152.18998053 ... 152.18998053 152.18998053\n",
      "  152.18998053]\n",
      " [149.40472779 149.40472779 149.40472779 ... 149.40472779 149.40472779\n",
      "  149.40472779]\n",
      " ...\n",
      " [143.64129714 143.64129714 143.64129714 ... 143.64129714 142.64129714\n",
      "  143.64129714]\n",
      " [157.55228028 158.55228028 158.55228028 ... 158.55228028 158.55228028\n",
      "  158.55228028]\n",
      " [145.8607941  145.8607941  145.8607941  ... 144.8607941  145.8607941\n",
      "  145.8607941 ]]\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "pNew, softmax = ForwardAndBackwardProp(miniBatch, y_miniBatch, p, 0.1, [784,300,10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d17b97c6-64a0-47b2-9501-c9d592155040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88079708, 0.88079708])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "212c4fcf-6fbf-47eb-865b-0f58848f911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.2155108823523"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loss(softmax, y_miniBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d0ab152-6443-49a7-bd65-64a5cc01b1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is verified: -0.049649173661237, this is acutal: 146.7262671358587\n",
      "Calculating dW2 another way: 146.8252676219906\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'W2OverTime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     pNew, softmax \u001b[38;5;241m=\u001b[39m ForwardAndBackwardProp(miniBatch, y_miniBatch, p, \u001b[38;5;241m0.001\u001b[39m, [\u001b[38;5;241m784\u001b[39m,\u001b[38;5;241m300\u001b[39m,\u001b[38;5;241m10\u001b[39m])\n\u001b[0;32m      9\u001b[0m     tempLoss \u001b[38;5;241m=\u001b[39m Loss(softmax, y_miniBatch)\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mW2OverTime\u001b[49m\u001b[38;5;241m.\u001b[39mappend(pNew[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(lossOverTime)\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlossOverTime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'W2OverTime' is not defined"
     ]
    }
   ],
   "source": [
    "#Putting it all together :), assuming all parameters are initialized\n",
    "epochs = 100\n",
    "lossOverTime = []\n",
    "softmaxOverTime = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    miniBatch, y_miniBatch = GetMiniBatch(x_train, 1000)\n",
    "    pNew, softmax = ForwardAndBackwardProp(miniBatch, y_miniBatch, p, 0.001, [784,300,10])\n",
    "    tempLoss = Loss(softmax, y_miniBatch)\n",
    "    W2OverTime.append(pNew[0][0,0])\n",
    "    \n",
    "plt.plot(lossOverTime)\n",
    "plt.title(\"lossOverTime\")\n",
    "plt.show()\n",
    "plt.plot(W2OverTime)\n",
    "plt.title(\"W2OverTime\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
